\chapter{Discussion}
\label{cha:discussion}

This chapter contains the following sub-headings.

\section{Results}
\label{sec:discussion-results}

% Are there anything in the results that stand out and need be
% analyzed and commented on? How do the results relate to the
% material covered in the theory chapter? What does the theory
% imply about the meaning of the results? For example, what
% does it mean that a certain system got a certain numeric value
% in a usability evaluation; how good or bad is it? Is there
% something in the results that is unexpected based on the
% literature review, or is everything as one would theoretically
% expect?

\subsection{Applicability to Real-world Search Scenarios}

\begin{itemize}
    \item Do the environments test realistic tasks?
    \item Is the needed number of training samples realistic?
    \item What happens when detection is more difficult?
    \item Real-world search has higher variance.
    \item Has the agent simply seen the full distribution, i.e. is it bridging any generalization gap?
\end{itemize}

\section{Method}
\label{sec:discussion-method}

% This is where the applied method is discussed and criticized.
% Taking a self-critical stance to the method used is an
% important part of the scientific approach.
% 
% A study is rarely perfect. There are almost always things one
% could have done differently if the study could be repeated or
% with extra resources. Go through the most important
% limitations with your method and discuss potential
% consequences for the results. Connect back to the method
% theory presented in the theory chapter. Refer explicitly to
% relevant sources.
% 
% The discussion shall also demonstrate an awareness of methodological
% concepts such as replicability, reliability, and validity. The concept
% of replicability has already been discussed in the Method chapter
% (\ref{cha:method}). Reliability is a term for whether one can expect
% to get the same results if a study is repeated with the same method. A
% study with a high degree of reliability has a large probability of
% leading to similar results if repeated. The concept of validity is,
% somewhat simplified, concerned with whether a performed measurement
% actually measures what one thinks is being measured. A study with a
% high degree of validity thus has a high level of credibility. A
% discussion of these concepts must be transferred to the actual context
% of the study.
% 
% The method discussion shall also contain a paragraph of
% source criticism. This is where the authorsâ€™ point of view on
% the use and selection of sources is described.
% 
% In certain contexts it may be the case that the most relevant
% information for the study is not to be found in scientific
% literature but rather with individual software developers and
% open source projects. It must then be clearly stated that
% efforts have been made to gain access to this information,
% e.g. by direct communication with developers and/or through
% discussion forums, etc. Efforts must also be made to indicate
% the lack of relevant research literature. The precise manner
% of such investigations must be clearly specified in a method
% section. The paragraph on source criticism must critically
% discuss these approaches.
% 
% Usually however, there are always relevant related research.
% If not about the actual research questions, there is certainly
% important information about the domain under study.

\subsection{Reinforcement Learning for Visual Search}

\begin{itemize}
    \item Is it a good idea to begin with?
    \item Other methods can potentially provide more guarantees.
    \item Connect back to \cite{dhiman_critical_2019}, who find that DRL is not able to exploit environment information to navigate more efficiently.
\end{itemize}

\subsection{Characteristics of Experimental Environments}

The three environments we have used to train and test searching agents are all quite different.

Notably, the camera environment does not follow the same 

\subsection{Reward Signal for Real-world Tasks}

\begin{itemize}
    \item Reward signal requires good knowledge of scene.
    \item As long as we have labelled scenes, we can use the reward.
\end{itemize}

\subsection{Evaluation and Comparison of Agents}

\begin{itemize}
    \item Is the comparison between spatial and temporal memory meaningful?
    \item Would have been nice with a comparison to a close-to-optimal rule-based baseline in each environment.
    \item Discussion about metrics, like SPL.
    \item What does the difference in SPL mean?
\end{itemize}

%Batra et al.~\cite{batra_evaluation_2020} revisit the problem of evaluating embodied navigation agents.
%They note some issues with the SPL metric.
%It fails to consider the fact that some failures are less of a failure than others.
%Some failures might in fact be close to reaching the goal while some fail completely.
%The binary success introduces high variance in average SPL computation.
%Furthermore, SPL is not particularly suitable for comparison across different datasets,
%as obtaining a high SPL is more difficult for short paths than for long paths.
%They suggest that SPL should be replaced by some metric that takes these issues into account.
%However, to our knowledge such a metric is yet to be proposed and widely adopted.

\subsection{Replicability, Reliability and Validity}

\begin{itemize}
    \item We have published source code.
    \item Reinforcement learning is inherently unreliable.
    \item Stochasticity necessary to avoid getting stuck, leads to less precise paths.
    \item Possibility of implementation errors.
    \item Low number of runs, quite high variance.
    \item Few samples during testing.
\end{itemize}

\subsection{Source Criticism}

\begin{itemize}
    \item We have based most of our work on known theory
\end{itemize}

\section{The work in a wider context}

% There must be a section discussing ethical and societal
% aspects related to the work. This is important for the authors
% to demonstrate a professional maturity and also for achieving
% the education goals. If the work, for some reason, completely
% lacks a connection to ethical or societal aspects this must be
% explicitly stated and justified in the section Delimitations in
% the introduction chapter.
% 
% In the discussion chapter, one must explicitly refer to sources
% relevant to the discussion.

\cite{vinuesa_sustainable_2020}

\cite{russell_priorities_2015}

\cite{russell_ethics_2015}

\cite{russell_beneficial_2022}

Visual search is ubiquitous in our daily lives as humans.
Automated visual search systems therefore naturally have many potential applications.
Furthermore, automating manual tasks has societal implications.

Several applications are positive, like search-and-rescue and fire detection.
In such scenarios, a short search time can be the difference between life and death.
Artificial intelligence systems have proven before that they are capable to outperform humans in specific tasks~\cite{silver_alphago_2016,vinyals_alphastar_2019}, and they could potentially do the same in visual search.

However, there automated visual search systems also have destructive applications.
A major concern of artificial intelligence researchers and the broader public today is the implications of autonomous systems for 

The widely discussed topic of autonomous weapon systems

% https://people.eecs.berkeley.edu/~russell/research/LAWS.html

As the authors of this work, we explicitly condemn its use for lethal weaponry.

\subsection{Trustworthiness for Critical Applications}


% what can this be used for? good and bad things?

%While automated search systems have many positive uses, like XXX, there are certainly other use cases that could be considered negative.
%Mass surveillance, XXX, are both very relevant today.



%It is worth considering whether using a learning agent like this is suitable for this task.
%One could imagine that it is possible to compute an optimal strategy for certain environments.
%However, this quickly falls apart.
%The dynamics of environments can vary considerably which may drastically affect how a manual approach is implemented.

%Another thing worth discussing is the possibility of combining manual search method with reinforcement learning. One could imagine combining a frontier based approach with a learning approach.

\rule{5cm}{1pt}

\begin{itemize}
    \item Evaluate generalization and viability for real world training sets. 
    \item Discuss advantages and disadvantages of RL for this task.
    \item The less bias we introduce, the more general the method has the potential to be.
    \item However, we could make the observation space clearer (for example, give the agent visited position directly).
    \item Search space size and its impact on performance.
    \item Larger search space could correspond to larger area or higher granularity.
    \item Is it better than exhaustive search?
    \item Is it better than a human?
    \item Not just visual search -- also a practical example of RL for exploration, generalization, \dots
    \item Stacked LSTM was unstable, even with dropout. Could it have remembered more?
    \item Differences in number of weights for different environment sizes\dots
    \item Comparison to exploration problems, other solutions methods?
    \item Camera movements in three dimensions: method could be expanded with higher-dimensional convolutions. 
    \item Discuss if indication is necessary
    \item Look into epsilon greedy
    \item Can gamma be used for quick exploration
    \item Rephrase target?
    \item Could give bad vibes...
    \item Greedy and random baselines have unfair advantage, but this is fine since we are not putting our method at an advantage.
    \item The map approach seems to scale better - with more time we could have trained for a larger search space.
    \item Neither scales well (weights in map scale increase quadratically with search space size -- fine for fixed positions, bad for movable cameras).
    \item If we find that bonuses speed up training but converge to poor solutions, we could discuss reward shaping. Remove bonus after convergence.
    \item The scene characteristics matter - in some cases, amortized probability of targets is not uniform, and patterns are more complex. We need more types of environments.
    \item Discuss the generality of the proposed approach - what types of cues can it pick up? Spatial and semantic relationships, non-uniform probabilities, etc. 
    \item An ego-centric architecture might be more general, does not need the position and can work over larger territories (although not take whole territory into account).
    \item Show some search paths and discuss them?
    \item The more specialized the reward, the higher the risk that it is good for some environments and bad for some. We saw with the unspecialized reward that it did not work well for the terrain environment. If we end up using only a specialized reward, discuss cases when it would not be able to find an optimal solution.
    \item Discuss lack of completion action (as suggested in related work).
    \item Talk about optimal paths and SPL (not realistic).
    \item Should have looked at more interesting environments (at least for optimal paths).
    \item Hopefully the camera environment is interesting.
    \item Early experiments with stacking multiple LSTM layers lead to heavy overfitting and unstable learning curves.
    \item The difficulty of each environment is related to the potential region targets can appear in. We can measure this in the environments themselves.
    \item We can visualize attention as in "A critical investigation of deep reinforcement learning for navigation"
    \item We have illustrated that reinforcement learning agents overfit to training samples and must be tested on separate sets.
    \item SPL metric
\end{itemize}

% learning actions, recognition and localization simultaneously feels in itself interesting
% how do we interpret such a model? are there papers for visualizing reinforcement learning weights
