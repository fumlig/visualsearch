\chapter{Results}
\label{cha:results}

This chapter presents the results for each of the experiments described in Section ~\ref{sec:experiments}.

\section{Quality of Search Behavior}

Table ~\ref{tab:metrics} shows the average search path length, success rate and SPL metric on a fixed set of 100 levels from each environment.
These metrics are presented for our two approaches trained on the full distribution of environments, as well as for the four baselines and human searchers.
Both the random and greedy baselines policies take search paths that are on average much longer than the number of positions in the search spaces for the respective environments.
This means that they take many redundant steps that revisit already explored positions.
The exhaustive policy avoids revisiting positions and achieves an average search path length that is below the total number of positions in each search space.

In all three environments, our two approaches as well as human searchers achieve higher SPL values than the three baselines.
The spatial memory agent achieves higher results than the temporal memory agent.
Furthermore, the temporal memory agent takes search paths that are longer than both the exhaustive baseline, the spatial memory agent, and a human searcher.
Human searchers seemed to be successful in utilizing using environment cues to guide search, but frequently forgot which positions had been visited.
The spatial memory achieves the highest SPL score in all three environments.
It also has the most competitive average search path length.

\begin{table}
    \centering
    \label{tab:metrics}
    \caption[Performance metrics for each environment.]{SPL, search path length and success rate from three runs on a fixed set of a 100 samples from each environment.}
    Gaussian environment\par\vspace{0.5em}
    \input{tables/metrics-gaussian}
    \par\vspace{1em}Terrain environment\par\vspace{0.5em}
    \input{tables/metrics-terrain}
    \par\vspace{1em}Camera environment\par\vspace{0.5em}
    \input{tables/metrics-camera}
\end{table}


\section{Size of Search Space}

The results of the search space experiments in the gaussian environment are presented in Figure~\ref{fig:shape}.
Results were collected across four different runs, and the plots show the mean and standard deviation.
For the search space of \(10 \times 10\), both architectures initially improve their policy quickly.
Past a certain time step, they keep improving at a reduced pace.
At the end of training, the spatial memory architecture has reached a policy that seems to find targets quicker than the temporal memory.
Both seem to be able to find the all three targets in every episode.

For the larger search space sizes with \(15 \times 15\) and \(20 \times 20\) the difference between the two architectures is greater.
While the spatial memory seems to consistently find targets in a number of steps that is comparable to the number of positions in the search space,
the search paths of the agent with the temporal memory are substantially longer.
Furthermore, the variance across runs increases with the search space size.

\begin{figure}
    \centering
    \(10 \times 10\)
    \input{figures/shape-10.pgf}
    \(15 \times 15\)
    \input{figures/shape-15.pgf}
    \(20 \times 20\)
    \input{figures/shape-20.pgf}
    \label{fig:shape}
    \caption[Learning curves for different search space sizes.]{Reward and episode length curves during training for three different search space sizes. Mean and standard deviation across 4 runs.}
\end{figure}

\section{Number of Training Samples}

Figure ~\ref{fig:sample} shows how the average length and success rate in the terrain environment is affected by the number of samples seen during training.
These metrics are presented for the limited training set and unlimited testing set respectively.

It seems like both architectures can overfit to training sets of as many as 1000 samples,
For smaller training set sizes, search path lengths on the test get get gradually worse past a certain time step.
Interestingly the LSTM architecture seems to overf<it more severely to small training sets.
Its performance on the test set decreases substantially past a certain time step.
The spatial memory architecture does not 
As many as 10000 training samples are needed to generalize to the full distribution of scenes and achieve the same performance on the training and test sets. 

\begin{figure}
    \centering
    \(500\) samples
    \input{figures/sample-500.pgf}
    \(100\) samples
    \input{figures/sample-1000.pgf}
    \(5000\) samples
    \input{figures/sample-5000.pgf}
    \(10000\) samples
    \input{figures/sample-10000.pgf}
    \label{fig:sample}
    \caption[Learning curves for different number of training samples.]{Reward and episode length curves for different training set sizes in terrain environment. Mean and standard deviation across 3 seeds.}
\end{figure}


%\section{Ablations}
%
%\dots