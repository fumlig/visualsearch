\section{Conclusion}

\begin{frame}
    \frametitle{Conclusion}

    \begin{itemize}
        \item General method for visual search with reinforcement learning.
        \item Three environments for evaluating visual search agents.
        \item Two different neural network architectures.
        \item Architecture affects performance, scaling and generalization.
        \item One approach comparable to human performance.
    \end{itemize}
\end{frame}

\subsection{Future Work}

\begin{frame}
    \frametitle{Future Work}

    \begin{itemize}
        \item Real-world scenarios.
        % We have looked at simulated environments which are easier to control.
        % Easier to vary parameters to get a sense of what is feasible.
        % The final goal is to use this for realistic scenarios.
        % There will be higher variance, difficult patterns, detection problems, noise.
        % Should see if this approach scales to such scenarios.
        % Is it enough to simply increase number of parameters?
        % Does the approach has to be modified?
        % Example: use a pretrained object detection network?
        \item Closer to optimal behaviors.
        % Neither agent was as good as a handcrafted baseline in one of the environments.
        % Why is this? How can we make the agent learn better policies?
        % Stochasticity? Other algorithm? Too much bias in reward? etc.
        \item Formal verification (for security-critical applications).
        % Handcrafted systems can offer more guarantees.
        % It is important to verify autonomous systems before deploying them.
        % This is especially true for safety-critical applications.
        % Value alignment etc.
        \item Hyperparameter tuning (expensive!).
        % maybe don't include this...
        % Can give quite different results.
        % Should be investigated.
        \item Other RL algorithms.
        % We have used proximal policy optimization.
        % A policy gradient algorithm which approximates the policy directly.
        % Such methods are known to not converge to global optima in general.
        % There are other algorithms with other characteristics. 
    \end{itemize}
\end{frame}