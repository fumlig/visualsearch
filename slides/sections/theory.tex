\section{Theory}

\subsection{Background}

\begin{frame}
    \frametitle{Partially Observable Markov Decision Process (POMDP)}

    % POMDP~\cite{kaelbling_planning_1998}: 
    \textit{Agent} interacts with \textit{environment} over discrete time steps. At each step \(t = 0, 1, 2\dots, T\):

    \begin{itemize}
        \item Environment is in state \(s_t\) that can not be observed by agent.
        \item Agent takes \textit{action} \(a_t\).
        \item Perceives partial \textit{observation} \(o_t\) of state.
        \item Receives scalar reward \(r_t\) that indicates whether action is good or bad.
        \item New state \(s_{t+1}\) depends only on history of interactions.
        \item State not available to agent, must maintain internal state \(\rightarrow\) memory.
    \end{itemize}

    \begin{figure}
        \centering
        \scalebox{0.75}{\input{figures/pomdp}}
    \end{figure}
\end{frame}

\begin{frame}
    \frametitle{Reinforcement Learning (RL)}

    % RL~\cite{sutton_reinforcement_2018}:
    Paradigm for learning from interactions how to achieve a goal.

    \begin{itemize}
        \item Policy \(\pi(a|s)\) is a mapping from states to action probabilities.
        \item Find policy that maximizes cumulative reward \(\mathbb{E} \left\lbrack \sum_{k=0}^{T} \gamma^{k-t-1} r_k \right\rbrack\).
        \item Several algorithms with different pros and cons.
    \end{itemize}

    Deep RL: Approximate \(\pi\) with deep neural networks. Used for complex tasks like Atari~\cite{mnih_human-level_2015}, Go~\cite{silver_mastering_2016}, StarCraft II~\cite{vinyals_grandmaster_2019}, etc.
\end{frame}

\subsection{Related Work}

\begin{frame}
    \frametitle{Related Work}

    Deep RL for similar tasks:

    \begin{itemize}
        \item Visual attention:
        \begin{itemize}
            \item Sequential focus points for foveated vision~\cite{mnih_recurrent_2014}.
        \end{itemize}
        \item Visual navigation:
        \begin{itemize}
            \item Solve random mazes~\cite{mirowski_learning_2017}.
            \item Find target object in indoor scenes~\cite{zhu_target-driven_2017}.
        \end{itemize}
        \item Object detection:
        \begin{itemize}
            \item Region proposals for object localization~\cite{caicedo_active_2015}.
            \item Contextual reasoning over spatial layout in scenes~\cite{chen_spatial_2017}.
            \item Anatomical landmark detection in medical images~\cite{ghesu_multi-scale_2019}.
        \end{itemize}
    \end{itemize}

    Missing: how visual cues can guide search, overfitting and generalization from limited samples, rigorous performance evaluation.
\end{frame}