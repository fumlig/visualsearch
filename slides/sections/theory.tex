\section{Theory}

\subsection{Background}

\begin{frame}
    \frametitle{Partially Observable Markov Decision Process (POMDP)}

    % Model the problem

    % POMDP~\cite{kaelbling_planning_1998}: 

    \begin{itemize}
        \item Formally description of environment.
        \item \textit{Agent} interacts with \textit{environment} over discrete time steps \(t = 0, 1, 2\dots, T\)
        \item Environment \textit{state} \(s_t\) can not be observed.
        \item Only partial \textit{observations}.
        \item Agent takes \textit{action} \(a_t\).
        \item Perceives partial \textit{observation} \(o_t\) of state.
        \item Receives scalar reward \(r_t\) that indicates whether action is good or bad.
        \item New state \(s_{t+1}\) depends only on history of interactions.
        \item State not available to agent, must maintain internal state \(\rightarrow\) memory.
    \end{itemize}

    \begin{figure}
        \centering
        \scalebox{0.75}{\input{figures/pomdp}}
    \end{figure}
\end{frame}

\begin{frame}
    \frametitle{Reinforcement Learning (RL)}

    % RL~\cite{sutton_reinforcement_2018}:
    Paradigm for learning from interactions how to achieve a goal.

    \begin{itemize}
        \item Policy \(\pi(a|s)\) is a mapping from states to action probabilities.
        \item Find policy that maximizes cumulative reward \(\mathbb{E} \left\lbrack \sum_{k=0}^{T} \gamma^{k-t-1} r_k \right\rbrack\).
        \item No inherent reward: design parameter!
        \item 
    \end{itemize}

    Deep RL: Approximate \(\pi\) with deep neural networks.
    % go into instability etc...
\end{frame}

\subsection{Related Work}

\begin{frame}
    \frametitle{Related Work}

    Deep RL for similar tasks:

    \begin{itemize}
        \item Visual attention:
        \begin{itemize}
            \item Sequential focus points for foveated vision~\cite{mnih_recurrent_2014}.
        \end{itemize}
        \item Visual navigation:
        \begin{itemize}
            \item Solve random mazes~\cite{mirowski_learning_2017}.
            \item Find target object in indoor scenes~\cite{zhu_target-driven_2017}.
        \end{itemize}
        \item Object detection:
        \begin{itemize}
            \item Region proposals for object localization~\cite{caicedo_active_2015}.
            \item Contextual reasoning over spatial layout in scenes~\cite{chen_spatial_2017}.
            \item Anatomical landmark detection in medical images~\cite{ghesu_multi-scale_2019}.
        \end{itemize}
    \end{itemize}

    Missing: how visual cues can guide search, overfitting and generalization from limited samples, rigorous performance evaluation.
\end{frame}